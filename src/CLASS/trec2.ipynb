{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whs1111/sentence-transformers/blob/master/src/CLASS/trec2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMb0U7ctSDcL",
        "colab_type": "code",
        "outputId": "b11a71b7-8ba4-41ce-b7f3-07b1dde4ac03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dBPVVL26Lyz",
        "colab_type": "code",
        "outputId": "ff1b488d-e2c7-486b-c2b8-c1bd32100440",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/gdrive/My Drive/Colab_Notebooks/code/bert-version/src/attention"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab_Notebooks/code/bert-version/src/attention\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUEyn78YBs5s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4XFda_IIpeM",
        "colab_type": "code",
        "outputId": "a39414a9-79ee-4cbc-e81d-d605b08dfa41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        }
      },
      "source": [
        "!pip  install -U sentence-transformers"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/32/e3d405806ea525fd74c2c79164c3f7bc0b0b9811f27990484c6d6874c76f/sentence-transformers-0.2.5.1.tar.gz (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 1.9MB/s \n",
            "\u001b[?25hCollecting transformers==2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/10/aeefced99c8a59d828a92cc11d213e2743212d3641c87c82d61b035a7d5c/transformers-2.3.0-py3-none-any.whl (447kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (4.28.1)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.4.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0->sentence-transformers) (2.21.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 12.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0->sentence-transformers) (1.11.15)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 19.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers) (0.14.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence-transformers) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->sentence-transformers) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->sentence-transformers) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.3.0->sentence-transformers) (7.0)\n",
            "Requirement already satisfied, skipping upgrade: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0->sentence-transformers) (1.14.15)\n",
            "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0->sentence-transformers) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0->sentence-transformers) (0.9.4)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers==2.3.0->sentence-transformers) (2.6.1)\n",
            "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers==2.3.0->sentence-transformers) (0.15.2)\n",
            "Building wheels for collected packages: sentence-transformers, sacremoses\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-0.2.5.1-cp36-none-any.whl size=67076 sha256=d70355bc8d8d86e8bf1eb892fe682aa4218ba824f918adfd23fecb49463fd7b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/ca/b4/7ca542b411730a8840f8e090df2ddacffa1c4dd9f209684c19\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=98fc8c6965b04870b4cc0716df01655849a75c262403416dbaececf33813df40\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sentence-transformers sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, transformers, sentence-transformers\n",
            "Successfully installed sacremoses-0.0.38 sentence-transformers-0.2.5.1 sentencepiece-0.1.85 transformers-2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwCPXJLxd27_",
        "colab_type": "code",
        "outputId": "3758a201-93d2-4feb-b57c-d96688f093e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('bert-base-nli-mean-tokens')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 405M/405M [00:45<00:00, 8.86MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1l6kCm5gbsGN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "60dd059d-0143-4efb-915a-370ae29248fc"
      },
      "source": [
        "import numpy as np\n",
        "text = np.load(\"./text.npy\",allow_pickle=True)\n",
        "print(text[1][1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2.49711767e-01 -2.82164723e-01  2.19010568e+00  2.11631909e-01\n",
            "  1.73209593e-01  6.94997609e-01  5.55487156e-01  5.46688318e-01\n",
            " -8.89633372e-02 -9.87455770e-02 -1.16353595e+00  2.98105955e-01\n",
            "  1.68292835e-01  7.38952458e-01  1.64602959e+00 -1.12340093e-01\n",
            " -5.72960079e-01 -8.61506984e-02  2.67076045e-01 -4.62193817e-01\n",
            "  6.16137125e-02  5.22885799e-01  2.17334330e-01 -1.01455653e+00\n",
            " -2.66425759e-01 -1.01824558e+00  2.38909602e-01 -2.04582405e+00\n",
            " -4.71447080e-01  3.02472919e-01  2.45558426e-01 -3.33619088e-01\n",
            "  4.00535375e-01  3.36782247e-01  2.11084351e-01  1.58693746e-01\n",
            " -8.32225025e-01  1.52798787e-01  4.91026277e-03 -1.68043360e-01\n",
            "  1.52563000e+00  4.65080768e-01  5.38139641e-01  5.24656296e-01\n",
            " -7.46053234e-02  1.63567096e-01  4.18965697e-01 -4.67923790e-01\n",
            " -3.94064456e-01 -1.65052891e+00 -9.52729166e-01 -5.47379315e-01\n",
            "  1.10358632e+00  6.21386707e-01 -5.98428190e-01 -5.36719620e-01\n",
            "  5.76287270e-01 -3.72501731e-01  4.04018730e-01  7.15555012e-01\n",
            "  9.56390917e-01 -3.18458736e-01  3.87538761e-01  9.50914443e-01\n",
            " -8.81564200e-01  3.71071815e-01 -2.30306819e-01 -9.69417915e-02\n",
            " -9.29196537e-01  5.38934171e-01  8.37712467e-01 -2.01587304e-01\n",
            " -5.09079136e-02  4.39328581e-01 -7.32257843e-01  9.83147789e-03\n",
            "  5.35288990e-01  2.93122172e-01  5.07273436e-01  6.90243483e-01\n",
            "  7.78082848e-01  2.05087140e-01  1.41541326e+00 -5.63762188e-02\n",
            " -6.28732622e-01  3.73625606e-01  4.00161296e-01  2.73211062e-01\n",
            " -1.82539904e+00  4.27231044e-01  3.56189907e-02  4.48987365e-01\n",
            "  2.96149760e-01  4.43654768e-02 -9.63928923e-02 -1.27660468e-01\n",
            "  2.75074840e-01  4.76807989e-02  4.49147463e-01 -9.64432180e-01\n",
            " -7.60843277e-01 -3.13696295e-01 -5.27247079e-02  5.08886091e-02\n",
            " -2.31807664e-01  1.45919120e-03 -3.09721917e-01 -3.16910416e-01\n",
            " -1.29758418e-01 -1.45524159e-01 -4.18885380e-01  5.37152708e-01\n",
            "  1.05288184e+00 -3.20308030e-01 -1.17751002e-01 -2.67086029e-01\n",
            " -1.34224379e+00  4.87139970e-02 -2.34008744e-01  8.87483597e-01\n",
            "  3.64859700e-01  5.15648663e-01 -1.99275002e-01 -4.83297437e-01\n",
            "  7.13301361e-01 -3.44070457e-02  5.62312663e-01 -9.34180200e-01\n",
            " -1.15678537e+00 -5.27612977e-02 -2.57363290e-01  6.07691765e-01\n",
            " -1.60227716e-01  5.02122454e-02 -4.31482643e-02 -4.29643005e-01\n",
            "  4.19319183e-01 -4.38343853e-01 -1.51266649e-04 -1.98513508e-01\n",
            " -1.18468964e+00  6.09129608e-01 -1.01587951e+00  8.15074444e-01\n",
            "  3.09210211e-01 -4.44833785e-01  9.19957235e-02  5.02693236e-01\n",
            "  3.10141835e-02  3.10243160e-01 -1.00212932e+00  5.42223752e-01\n",
            "  4.58285026e-02 -1.02698199e-01 -1.06762183e+00 -3.40858936e-01\n",
            "  2.36983493e-01  1.36339438e+00  5.42651951e-01 -4.75570373e-02\n",
            "  2.58695036e-01  7.11457014e-01  6.10038877e-01 -2.83853412e-01\n",
            "  6.03545010e-01 -5.27707636e-01  3.51573527e-03  2.50003159e-01\n",
            "  6.49727523e-01 -7.46823967e-01  8.71429980e-01 -1.51231480e+00\n",
            "  5.31539917e-02  6.51407242e-02 -6.67447746e-01  7.56691769e-03\n",
            "  3.82172227e-01  1.02743351e+00  8.51591766e-01 -1.46400347e-01\n",
            "  9.05077830e-02  4.70444672e-02  1.44104779e+00 -1.59474802e+00\n",
            " -4.44929600e-01 -3.66412550e-01 -1.10881306e-01 -4.26556319e-01\n",
            "  1.11085780e-01  6.41993344e-01 -4.61017370e-01 -6.02139890e-01\n",
            "  5.05795300e-01 -1.01557732e+00  4.06212360e-01  1.68056309e-01\n",
            " -1.95097327e-01 -3.50244492e-01 -4.05813940e-02  1.06952459e-01\n",
            "  1.00882006e+00 -1.06330001e+00  2.34295249e-01 -4.90687154e-02\n",
            "  8.03927958e-01  1.72554457e+00 -7.28134632e-01 -2.59060591e-01\n",
            "  2.25297526e-01 -2.87273943e-01 -6.80486262e-01  1.97876051e-01\n",
            "  6.84137762e-01  6.52726352e-01  4.06769037e-01 -6.38283730e-01\n",
            "  1.25649250e+00 -6.52767599e-01 -1.19982326e+00  2.94652373e-01\n",
            "  3.92873883e-01 -1.19779706e-01  4.21691895e-01  1.92281768e-01\n",
            " -1.23277760e+00  9.16498840e-01  1.93362191e-01  2.90228814e-01\n",
            " -2.13706151e-01 -7.58093536e-01  3.54638487e-01 -1.23194665e-01\n",
            " -7.88282454e-01  8.33407640e-01  3.90496224e-01  8.12474918e-03\n",
            "  6.87675059e-01 -9.48657930e-01 -5.18675029e-01  2.54899830e-01\n",
            "  2.47474670e-01  9.70327795e-01  6.39549673e-01  1.04015553e+00\n",
            " -1.87386000e+00 -3.61926943e-01  9.43332016e-01 -6.16694629e-01\n",
            " -4.72601175e-01  1.01995182e+00  1.95868090e-01 -1.12112057e+00\n",
            " -3.02953869e-02 -5.78889512e-02 -6.37908638e-01 -3.52852851e-01\n",
            " -1.93246111e-01 -4.23137575e-01 -2.48739526e-01 -1.29467142e+00\n",
            " -6.42012775e-01 -1.20954297e-01 -1.57084182e-01 -1.76696572e-02\n",
            "  2.95166895e-02 -4.74810094e-01 -4.57541257e-01 -5.97121827e-02\n",
            "  3.90395448e-02  8.90256986e-02  6.19859695e-02 -5.48986614e-01\n",
            " -2.15544760e-01 -1.11013269e+00 -5.75720370e-01 -1.51226714e-01\n",
            "  1.07996595e+00  2.15106487e-01 -1.09913111e+00 -2.83566773e-01\n",
            "  1.43210471e-01  2.26288021e-01 -2.10256219e+00  4.29981232e-01\n",
            " -2.68539786e-01  1.41371831e-01  7.31927156e-01 -9.56622064e-01\n",
            " -1.42553911e-01  4.05442506e-01 -5.21169186e-01  5.79466820e-01\n",
            "  8.68743733e-02 -1.18421030e+00  5.25089264e-01 -5.30133545e-01\n",
            " -5.47632165e-02 -2.09975943e-01 -1.15673363e+00  7.65697777e-01\n",
            " -4.39579815e-01 -5.64161420e-01 -5.93471169e-01  5.13800204e-01\n",
            "  1.71943262e-01 -4.91118670e-01 -4.47088122e-01  4.89951849e-01\n",
            " -9.43876982e-01 -1.48406699e-01 -1.45949996e+00 -5.64439483e-02\n",
            "  6.19954109e-01 -1.88259959e-01  6.16905689e-01  5.45827895e-02\n",
            " -8.97820175e-01  1.79614604e-01 -9.08310711e-02 -9.78093922e-01\n",
            "  1.19418927e-01  4.01023388e-01 -2.95556694e-01 -3.48323464e-01\n",
            "  3.08214098e-01  1.54871181e-01 -2.58837730e-01  8.11445892e-01\n",
            " -3.57316881e-01 -2.01828673e-01  5.46157777e-01 -5.17107666e-01\n",
            " -2.02326346e-02  5.80022097e-01 -1.63741231e-01  1.19147456e+00\n",
            " -1.58271357e-01 -9.78326321e-01  3.60597223e-01  1.85298428e-01\n",
            " -3.46435398e-01 -7.08059609e-01 -1.57787591e-01 -1.36201322e-01\n",
            "  1.34180868e+00 -7.42778122e-01 -4.47430015e-01 -1.25609100e+00\n",
            "  8.40038061e-01  5.80548830e-02 -4.18635368e-01  5.77905834e-01\n",
            " -1.06922042e+00  4.05294985e-01 -6.65305555e-01 -9.32886422e-01\n",
            "  5.44544876e-01 -1.81505382e-01 -1.83800280e-01  4.39478070e-01\n",
            " -1.65142387e-01 -2.92143729e-02  7.23401383e-02 -3.76447827e-01\n",
            " -2.25481734e-01 -3.80821943e-01  8.59319270e-01 -1.85927078e-01\n",
            "  1.53821671e+00  2.39237472e-01  4.71852809e-01 -6.01363957e-01\n",
            "  5.21311574e-02 -1.17117725e-01 -1.93640664e-01 -1.54466867e-01\n",
            "  6.50680125e-01 -4.82281357e-01 -2.31402948e-01 -4.04906273e-01\n",
            "  4.07695740e-01 -1.02118957e+00 -2.21675575e-01 -8.14474896e-02\n",
            "  4.40323979e-01  5.58874607e-02 -4.67587113e-01 -1.05971634e+00\n",
            "  1.84853300e-01  1.18309736e-01  9.38560188e-01  6.24596775e-01\n",
            " -2.77053595e-01 -5.98077953e-04  2.30212510e-01 -1.72751617e+00\n",
            "  4.43025023e-01  9.29863930e-01  2.51380920e-01  6.43775165e-01\n",
            "  7.14823082e-02  4.64523047e-01  7.81661645e-02  2.17572033e-01\n",
            "  6.95771754e-01  3.24211754e-02 -4.23466772e-01 -5.21694236e-02\n",
            " -7.16348410e-01 -5.75516045e-01  2.34546661e-01  1.98571622e-01\n",
            " -1.39557755e+00 -1.25897482e-01 -5.82663059e-01  7.77924001e-01\n",
            " -3.36894482e-01 -6.38955295e-01  8.19755971e-01  4.50025946e-01\n",
            " -5.23489892e-01 -3.69059205e-01 -3.93429428e-01 -1.96987048e-01\n",
            " -7.74357021e-01  5.74435055e-01 -3.76043200e-01  1.00713737e-01\n",
            "  1.33243725e-02  1.62021462e-02 -2.27168515e-01  8.91167298e-02\n",
            " -8.47946346e-01  3.19439441e-01 -1.49063542e-01 -9.91187632e-01\n",
            " -5.43925762e-01 -2.80118912e-01 -3.04916739e-01 -5.49372137e-02\n",
            "  5.39855957e-01 -2.21303310e-02 -4.34505016e-01  1.72682241e-01\n",
            " -2.39007220e-01 -1.28165752e-01 -4.16723758e-01  5.17869107e-02\n",
            "  6.59510717e-02  4.39108573e-02  1.31265715e-01  1.00565434e+00\n",
            "  1.65824238e-02  4.38928217e-01  9.44344819e-01  1.83920145e-01\n",
            "  1.71836659e-01  7.08783388e-01  7.16524780e-01 -8.22780132e-01\n",
            "  3.74304742e-01 -2.09116235e-01 -9.54867184e-01 -2.71960616e-01\n",
            " -4.11664575e-01 -5.42314708e-01 -7.66573966e-01  6.76955879e-01\n",
            " -1.70125648e-01  4.53367859e-01 -2.38016486e-01  1.92396343e-01\n",
            "  5.30667245e-01 -4.13600296e-01  1.31794497e-01  1.06605041e+00\n",
            " -1.92314184e+00  3.85385416e-02  3.83100063e-01  3.29386860e-01\n",
            "  2.97301441e-01  1.02221107e+00 -3.10425431e-01 -3.00917000e-01\n",
            " -6.00493908e-01  5.48052132e-01  6.80829525e-01  2.09563076e-01\n",
            "  1.35424519e+00  3.29744369e-01 -5.84502280e-01 -8.55066597e-01\n",
            " -8.94245446e-01 -6.61136091e-01 -2.78035551e-01  9.65061665e-01\n",
            " -3.98043960e-01  1.47307292e-01  2.91369885e-01 -9.17458534e-03\n",
            " -2.04469655e-02  2.66017169e-01 -1.26636016e+00 -7.04573810e-01\n",
            "  2.52836585e-01  5.00012636e-01  5.46659417e-02  3.80561113e-01\n",
            "  4.28220361e-01  6.81997120e-01 -5.86421013e-01  1.16876137e+00\n",
            " -6.71728134e-01 -3.53424214e-02 -4.09439683e-01 -6.97090209e-01\n",
            "  4.15955514e-01  3.24970305e-01  7.00773776e-01 -7.85546541e-01\n",
            "  5.11845052e-02  6.18247353e-02 -1.97222792e-02  3.99969220e-01\n",
            "  7.41843224e-01 -3.48321557e-01 -3.49412896e-02 -1.96799278e-01\n",
            "  3.26423734e-01 -3.11550647e-01  4.64742094e-01  4.14353721e-02\n",
            " -1.04197562e-02  3.78022105e-01  7.68979251e-01  1.00506097e-01\n",
            " -1.61910638e-01 -3.98484111e-01  1.25360526e-02  1.41200051e-01\n",
            "  3.70190948e-01  4.14167255e-01  6.87553704e-01 -8.36832225e-01\n",
            " -5.68750679e-01  2.56968528e-01 -4.49781269e-01 -4.11480039e-01\n",
            "  4.82750624e-01 -1.05385482e+00 -3.01928043e-01  3.98000330e-01\n",
            " -1.91842735e-01 -3.80220085e-01  5.70978642e-01 -8.06222618e-01\n",
            "  5.58013916e-01  7.89920807e-01 -3.33644956e-01 -1.07224369e+00\n",
            "  1.89648628e-01 -3.43501955e-01  2.87105948e-01 -4.28882748e-01\n",
            " -3.40166330e-01  2.35731434e-02 -9.46704522e-02  4.58734274e-01\n",
            "  2.66431332e-01 -1.57282650e-02  5.84368855e-02 -3.32370728e-01\n",
            "  1.00893043e-01  6.18115485e-01 -4.23538476e-01  5.04181767e-03\n",
            "  1.00938129e+00 -2.25779891e-01 -1.84937847e+00 -3.09987038e-01\n",
            "  8.62797797e-01  9.39557850e-01  4.32062715e-01 -9.41911399e-01\n",
            " -3.19114655e-01  1.54051557e-01  3.11430275e-01 -1.04444933e+00\n",
            "  6.22632861e-01  1.25908220e+00  3.35628748e-01 -2.74416417e-01\n",
            " -7.83044770e-02 -7.56714404e-01  8.70931447e-01 -1.45037428e-01\n",
            " -3.07475358e-01  5.28685510e-01 -3.93290073e-03  2.18719110e-01\n",
            " -1.58037081e-01 -1.75467625e-01 -9.64334548e-01  7.00787306e-01\n",
            " -3.90101880e-01 -4.95777875e-02 -8.70515928e-02 -2.73505330e-01\n",
            " -5.79491556e-01  2.98604548e-01  4.83791828e-01 -4.74353284e-01\n",
            " -4.18193489e-01  5.89913428e-02 -5.44476807e-01 -6.92384064e-01\n",
            " -5.48416853e-01  5.16603768e-01  1.34242380e+00  3.76772642e-01\n",
            " -2.26839498e-01  2.30085686e-01 -2.70013828e-02  3.25383306e-01\n",
            " -1.49766818e-01 -7.52395928e-01  4.15423393e-01 -5.26474297e-01\n",
            " -8.51811096e-02  4.92425561e-01  4.81881112e-01  7.65840232e-01\n",
            "  9.03403103e-01  8.22091103e-01 -2.36698195e-01  6.78101957e-01\n",
            "  5.75753868e-01  2.47128248e-01  5.96042722e-04 -4.46406156e-01\n",
            "  8.10622424e-02 -5.71902752e-01  8.86193693e-01 -4.10036296e-01\n",
            "  1.40722975e-01 -6.74588501e-01 -4.12534237e-01  4.86314774e-01\n",
            "  6.46169305e-01  2.27844849e-01  1.58323675e-01 -1.24763870e+00\n",
            " -7.19311714e-01  1.24349266e-01  3.53692502e-01 -3.84341031e-01\n",
            " -3.06527466e-01  3.69424015e-01 -4.44191933e-01 -1.35312879e+00\n",
            "  2.64971495e-01 -9.97617841e-02 -2.11342975e-01 -2.66621619e-01\n",
            " -1.66459251e-02  4.05921698e-01 -1.75601229e-01 -7.51688659e-01\n",
            " -8.29405606e-01  9.65355560e-02  4.34910297e-01  2.23772660e-01\n",
            "  2.99621493e-01 -9.13516521e-01 -3.64379287e-01 -1.35897085e-01\n",
            "  1.14887822e+00 -5.08791506e-01  5.14209032e-01 -4.00201648e-01\n",
            "  1.80243623e+00  6.90150261e-01 -9.14329067e-02  3.00800711e-01\n",
            "  1.89704731e-01 -4.02734488e-01 -1.56101780e-02 -2.35405281e-01\n",
            " -4.13291961e-01 -1.86782554e-01  7.90060520e-01  2.38080978e-01\n",
            "  3.48031402e-01 -1.58288538e+00  1.45799980e-01  8.42710733e-01\n",
            " -5.52475341e-02 -4.52115685e-01  1.27867624e-01 -8.06100845e-01\n",
            " -8.38855982e-01 -7.79299319e-01 -1.14495039e+00  1.11332893e+00\n",
            " -5.52571058e-01 -5.63359439e-01 -8.09618473e-01  1.38532624e-01\n",
            "  4.15349007e-01  5.18776894e-01 -5.17047681e-02  9.77750719e-01\n",
            " -5.74267864e-01  1.06548071e+00  2.62859434e-01  1.76088464e+00\n",
            "  2.21486241e-02 -1.26879916e-01  5.29829741e-01 -6.19575083e-01\n",
            " -2.43562367e-02  1.83716193e-01 -6.66518748e-01  1.31545812e-01\n",
            " -6.35163605e-01 -1.20546915e-01 -4.47903842e-01 -1.58930123e-01\n",
            " -8.80483449e-01 -8.05635750e-01 -6.29483998e-01  3.58850956e-01\n",
            " -6.21783316e-01  4.99109238e-01  7.29789555e-01  3.25619549e-01\n",
            "  4.36144441e-01  2.34428898e-01 -3.99563648e-02  4.34389681e-01\n",
            " -4.71269846e-01 -3.96774888e-01  7.00260639e-01 -1.43739641e-01\n",
            " -7.79177919e-02 -2.81753898e-01  3.06609660e-01  1.96073890e-01\n",
            " -1.01719034e+00  3.99646550e-01  1.93070900e-02  1.05579865e+00\n",
            " -7.96689570e-01 -1.29512000e+00 -7.65715837e-01 -4.28954273e-01\n",
            "  1.20274752e-01 -1.40155539e-01  8.08136225e-01  2.35901609e-01\n",
            "  5.62694728e-01  4.07669991e-01 -4.57572252e-01 -5.33301711e-01\n",
            "  6.72814786e-01  1.88007668e-01  3.35017294e-01  4.37008739e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLprvVUK458L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "label_list = [\"GoodsServices\",\n",
        "        \"SearchAndRescue\",\n",
        "        \"InformationWanted\",\n",
        "        \"Volunteer\",\n",
        "        \"FundRaising\",\n",
        "        \"Donations\",\n",
        "        \"MovePeople\",\n",
        "        \"FirstPartyObservation\",\n",
        "        \"ThirdPartyObservation\",\n",
        "        \"Weather\",\n",
        "        \"EmergingThreats\",\n",
        "        \"NewSubEvent\",\n",
        "        \"MultimediaShare\",\n",
        "        \"ServiceAvailable\",\n",
        "        \"Factoid\",\n",
        "        \"Official\",\n",
        "        \"CleanUp\",\n",
        "        \"Hashtags\",\n",
        "        \"ContextualInformation\",\n",
        "        \"News\",\n",
        "        \"Advice\",\n",
        "        \"Sentiment\",\n",
        "        \"Discussion\",\n",
        "        \"Irrelevant\",\n",
        "        \"OriginalEvent\"]\n",
        "important_list = [\"Low\",\n",
        "        \"Medium\",\n",
        "        \"High\",\n",
        "        \"Critical\"\n",
        "       ]\n",
        "tweets = []\n",
        "path = '/content/gdrive/My Drive/Colab_Notebooks/code/bert-version/src/DATA/ll.csv'\n",
        "with open(path, 'r', encoding='utf-8') as f:\n",
        "    reader = csv.reader(f)\n",
        "    for line in reader:\n",
        "        tweet_full = line\n",
        "        tweets.append({\n",
        "            'id': tweet_full[0],\n",
        "            'label':tweet_full[1],\n",
        "            'important':tweet_full[2],\n",
        "            'text': tweet_full[3].lower(),\n",
        "            # 'name': tweet_full['user']['name'].split()[0]\n",
        "            })\n",
        "tweet_list = []\n",
        "text_list = []\n",
        "for i in range(len(tweets)):\n",
        "        text_list.append(tweets[i]['text'])\n",
        "        tweets_vector = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "        tweets_label = eval(tweets[i]['label'])\n",
        "        p = 0\n",
        "        for j in label_list:\n",
        "            for k in tweets_label:\n",
        "                if k == j:\n",
        "                    tweets_vector[p] = 1\n",
        "            p+=1\n",
        "        tweet_list.append(tweets_vector)\n",
        "text_numpy = model.encode(text_list)\n",
        "numpy_label_list = np.array(tweet_list)\n",
        "numpy_text_list = np.array(text_numpy)\n",
        "np.save('./label.npy',numpy_label_list)\n",
        "np.save('./text.npy',numpy_text_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cB8lQscg6JS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "lr = 0.001\n",
        "epochs = 1000\n",
        "batch_size = 16\n",
        "seed = 1111\n",
        "cuda_able = True\n",
        "save = \n",
        "dropout = 0.5\n",
        "embed_dim = 64\n",
        "hidden_size = 32\n",
        "bidirectional = True\n",
        "weight_decay = 0.001\n",
        "attention_size = 16\n",
        "sequence_length = 16\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "use_cuda = torch.cuda.is_available() and cuda_able\n",
        "\n",
        "\n",
        "###################################################\n",
        "#load data\n",
        "\n",
        "from data_loder import DataLoader\n",
        "\n",
        "data = np.load(\"./data/text.npy\")\n",
        "label = np.load(\"./data/label.npy\")\n",
        "\n",
        "\n",
        "\n",
        "training_data = DataLoader(data,\n",
        "                           label,\n",
        "                           batch_size=batch_size,\n",
        "                           cuda=use_cuda)\n",
        "validation_data = DataLoader(data,\n",
        "                             label,\n",
        "                             batch_size=batch_size,\n",
        "                             shuffle=False,\n",
        "                             cuda=use_cuda)\n",
        "\n",
        "\n",
        "###############################################\n",
        "#build model\n",
        "\n",
        "import model\n",
        "lstm_attn = model.bilstm_attn(batch_size=batch_size,\n",
        "                                  output_size=output_size,\n",
        "                                  hidden_size=hidden_size,\n",
        "                                  vocab_size=vocab_size,\n",
        "                                  embed_dim=embed_dim,\n",
        "                                  bidirectional=bidirectional,\n",
        "                                  dropout=dropout,\n",
        "                                  use_cuda=use_cuda,\n",
        "                                  attention_size=attention_size,\n",
        "                                  sequence_length=sequence_length)\n",
        "if use_cuda:\n",
        "    lstm_attn = lstm_attn.cuda()\n",
        "\n",
        "optimizer = torch.optim.Adam(lstm_attn.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "###################################################\n",
        "#training\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "train_loss = []\n",
        "valid_loss = []\n",
        "accuracy = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def evaluate():\n",
        "    lstm_attn.eval()\n",
        "    corrects = eval_loss = 0\n",
        "    _size = validation_data.sents_size\n",
        "\n",
        "    for data, label in tqdm(validation_data, mininterval=0.2,\n",
        "                desc='Evaluate Processing', leave=False):\n",
        "\n",
        "        pred = lstm_attn(data)\n",
        "        loss = criterion(pred, label)\n",
        "\n",
        "        eval_loss += loss.data\n",
        "        corrects += (torch.max(pred, 1)[1].view(label.size()).data == label.data).sum()\n",
        "    return eval_loss[0]/_size, corrects, corrects*100.0/_size, _size\n",
        "\n",
        "\n",
        "def train():\n",
        "    lstm_attn.train()\n",
        "    total_loss = 0\n",
        "    for data, label in tqdm(training_data, mininterval=1,\n",
        "                desc='Train Processing', leave=False):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        target = lstm_attn(data)\n",
        "        loss = criterion(target, label)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.data\n",
        "    return total_loss[0]/training_data.sents_size\n",
        "\n",
        "#################################################\n",
        "#saving\n",
        "best_acc = None\n",
        "total_start_time = time.time()\n",
        "\n",
        "try:\n",
        "    print('-' * 90)\n",
        "    for epoch in range(1, epochs+1):\n",
        "        epoch_start_time = time.time()\n",
        "        loss = train()\n",
        "        train_loss.append(loss*1000.)\n",
        "\n",
        "        print('| start of epoch {:3d} | time: {:2.2f}s | loss {:5.6f}'.format(epoch,\n",
        "                                                                              time.time() - epoch_start_time,\n",
        "                                                                              loss))\n",
        "\n",
        "        loss, corrects, acc, size = evaluate()\n",
        "        valid_loss.append(loss*1000.)\n",
        "        accuracy.append(acc)\n",
        "\n",
        "        print('-' * 10)\n",
        "        print('| end of epoch {:3d} | time: {:2.2f}s | loss {:.4f} | accuracy {}%({}/{})'.format(epoch,\n",
        "                                                                                                 time.time() - epoch_start_time,\n",
        "                                                                                                 loss,\n",
        "                                                                                                 acc,\n",
        "                                                                                                 corrects,\n",
        "                                                                                                 size))\n",
        "        print('-' * 10)\n",
        "        if not best_acc or best_acc < corrects:\n",
        "            best_acc = corrects\n",
        "            model_state_dict = lstm_attn.state_dict()\n",
        "            model_source = {\n",
        "                \"model\": model_state_dict,\n",
        "                \"src_dict\": data['dict']['train']\n",
        "            }\n",
        "            torch.save(model_source, save)\n",
        "except KeyboardInterrupt:\n",
        "    print(\"-\"*90)\n",
        "    print(\"Exiting from training early | cost time: {:5.2f}min\".format((time.time() - total_start_time)/60.0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gWoWziH5-c3",
        "colab_type": "text"
      },
      "source": [
        "# 新段落"
      ]
    }
  ]
}