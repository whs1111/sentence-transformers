{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whs1111/sentence-transformers/blob/master/src/CLASS/trec5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMb0U7ctSDcL",
        "colab_type": "code",
        "outputId": "e96bd723-0672-4b05-e272-3c0aec565d9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dBPVVL26Lyz",
        "colab_type": "code",
        "outputId": "9c7d5851-2da5-49e4-c5c3-eaf1e187c25f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/gdrive/My Drive/Colab_Notebooks/code/bert-version/src/attention"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab_Notebooks/code/bert-version/src/attention\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdZjkab-PZ7i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LabelTable = {}\n",
        "LabelTable[\"GoodsServices\"] = [\"Request-GoodsServices\", \"Request\", \"The user is asking for a particular service or physical good.\", 0]\n",
        "LabelTable[\"SearchAndRescue\"] = [\"Request-SearchAndRescue\", \"Request\", \"The user is requesting a rescue (for themselves or others)\", 1]\n",
        "LabelTable[\"InformationWanted\"] = [\"Request-InformationWanted\", \"Request\", \"The user is requesting informationd\", 2]\n",
        "LabelTable[\"Volunteer\"] = [\"CallToAction-Volunteer\", \"Call to action\", \"The user is asking people to volunteer to help the response effort\", 3]\n",
        "LabelTable[\"Donations\"] = [\"CallToAction-Donations\", \"Call to action\", \"The user is asking people to donate goods/money\", 4]\n",
        "LabelTable[\"MovePeople\"] = [\"CallToAction-MovePeople\", \"Call to action\", \"The user is asking people to leave an area or go to another area\", 5]\n",
        "LabelTable[\"FirstPartyObservation\"] = [\"Report-FirstPartyObservation\", \"report\", \"The user is giving an eye-witness account\", 6]\n",
        "LabelTable[\"ThirdPartyObservation\"] = [\"Report-ThirdPartyObservation\", \"report\", \"The user is reporting a information that they received from someone else\", 7]\n",
        "LabelTable[\"Weather\"] = [\"Report-Weather\", \"report\", \"The user is providing a weather report (current or forecast)\", 8]\n",
        "LabelTable[\"EmergingThreats\"] = [\"Report-EmergingThreats\", \"report\", \"The user is reporting a potential problem that may cause future loss of life or damage\", 9]\n",
        "LabelTable[\"SignificantEventChange\"] = [\"Report-SignificantEventChange\", \"report\", \"The user is reporting a new occuirrence that public safety officers need to respond to.\", 10]\n",
        "LabelTable[\"MultimediaShare\"] = [\"Report-MultimediaShare\", \"report\", \"The user is sharing images or video\", 11]\n",
        "LabelTable[\"ServiceAvailable\"] = [\"Report-ServiceAvailable\", \"report\", \"The user is reporting that they or someone else is providing a service\", 12]\n",
        "LabelTable[\"Factoid\"] = [\"Report-Factoid\", \"report\", \"The user is relating some facts, typically numerical\", 13]\n",
        "LabelTable[\"Official\"] = [\"Report-Official\", \"report\", \"An official report by a government or public safety representative\", 14]\n",
        "LabelTable[\"CleanUp\"] = [\"Report-CleanUp\", \"report\", \"A report of the clean up after the event\", 15]\n",
        "LabelTable[\"Hashtags\"] = [\"Report-Hashtags\", \"report\", \"Reporting which hashtags correspond to each event\", 16]\n",
        "LabelTable[\"PastNews\"] = [\"Other-PastNews\", \"other\", \"The post is generic news, e.g. reporting that the event occurred\", 17]\n",
        "LabelTable[\"ContinuingNews\"] = [\"Other-ContinuingNews\", \"other\", \"The post providing/linking to continious coverage of the event\", 18]\n",
        "LabelTable[\"Advice\"] = [\"Other-Advice\", \"other\", \"The  author is providing some advice to the public\", 19]\n",
        "LabelTable[\"Sentiment\"] = [\"Other-Sentiment\", \"other\", \"The post is expressing some sentiment about the event\", 20]\n",
        "LabelTable[\"Discussion\"] = [\"Other-Discussion\", \"other\", \"Users are discussing the event\", 21]\n",
        "LabelTable[\"Irrelevant\"] = [\"Other-Irrelevant\", \"other\", \"The post is irrelevant, contains no information\", 22]\n",
        "LabelTable[\"Unknown\"] = [\"Other-Unknown\", \"other\", \"Does not fit into any other category\", 23]\n",
        "LabelTable[\"KnownAlready\"] = [\"Other-KnownAlready\", \"other\", \"The Responder already knows this information\", 24]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUEyn78YBs5s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4XFda_IIpeM",
        "colab_type": "code",
        "outputId": "16b65482-af07-40f5-9d9d-f354c40e99d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        }
      },
      "source": [
        "!pip  install -U sentence-transformers"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/32/e3d405806ea525fd74c2c79164c3f7bc0b0b9811f27990484c6d6874c76f/sentence-transformers-0.2.5.1.tar.gz (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 4.2MB/s \n",
            "\u001b[?25hCollecting transformers==2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/10/aeefced99c8a59d828a92cc11d213e2743212d3641c87c82d61b035a7d5c/transformers-2.3.0-py3-none-any.whl (447kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 18.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (4.28.1)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.4.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.18.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 48.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0->sentence-transformers) (1.12.18)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 29.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0->sentence-transformers) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers) (0.14.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence-transformers) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.3.0->sentence-transformers) (7.1.1)\n",
            "Requirement already satisfied, skipping upgrade: botocore<1.16.0,>=1.15.18 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0->sentence-transformers) (1.15.18)\n",
            "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0->sentence-transformers) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0->sentence-transformers) (0.9.5)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->sentence-transformers) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->sentence-transformers) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.18->boto3->transformers==2.3.0->sentence-transformers) (0.15.2)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.18->boto3->transformers==2.3.0->sentence-transformers) (2.8.1)\n",
            "Building wheels for collected packages: sentence-transformers, sacremoses\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-0.2.5.1-cp36-none-any.whl size=67076 sha256=aaea927d9cdd98eadf2f5ac1a04589dfc74d6415f450ca5800a7a840037dd7a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/ca/b4/7ca542b411730a8840f8e090df2ddacffa1c4dd9f209684c19\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=0360ed525d2f339f9aa354576b2e16ea52db59c29efb93d7584ba58a096e6586\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sentence-transformers sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, transformers, sentence-transformers\n",
            "Successfully installed sacremoses-0.0.38 sentence-transformers-0.2.5.1 sentencepiece-0.1.85 transformers-2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwCPXJLxd27_",
        "colab_type": "code",
        "outputId": "2059c3b3-e291-4aa4-afc7-71937aaa48ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('bert-base-nli-mean-tokens')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 405M/405M [00:06<00:00, 59.1MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1l6kCm5gbsGN",
        "colab_type": "code",
        "outputId": "825cb9d5-74af-4e49-ff5f-39f1cdd35be5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "text = np.load(\"./data/label_text.npy\",allow_pickle=True)\n",
        "print(text[1])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1.29892462e+00  8.01876336e-02  3.27284396e+00 -7.42400736e-02\n",
            " -1.53139248e-01  1.26809601e+00 -7.43034691e-01  3.62462876e-01\n",
            " -1.30001247e-01 -6.35710761e-01 -8.20930630e-01  8.33184965e-01\n",
            "  7.99960196e-01  1.41218752e+00 -1.71086597e+00 -3.09613816e-01\n",
            " -6.65210903e-01 -8.27717945e-01  5.54650605e-01 -1.08262834e+00\n",
            " -9.59268168e-01 -1.73800839e-02  3.70711131e-01 -2.05403864e-02\n",
            " -5.98856788e-01 -9.98228788e-03 -5.18390998e-01 -1.27084798e+00\n",
            " -6.10516146e-01 -1.83383644e-01 -2.95221433e-01  4.71605569e-01\n",
            "  1.07024938e+00 -4.35325930e-01 -1.30751845e+00  5.94622791e-02\n",
            "  2.31171560e+00 -6.54108614e-01  1.29427213e-01  8.97169739e-01\n",
            " -4.96304832e-01 -5.21741256e-01  1.51500878e+00  2.03628612e+00\n",
            " -1.69350320e+00 -1.10695654e+00  7.39154354e-01  6.90971732e-01\n",
            " -1.21120327e+00 -1.25300752e+00 -1.06642289e+00 -5.49089670e-01\n",
            "  2.32510567e-02  1.62906426e+00 -8.55856895e-01  1.83341986e+00\n",
            " -3.90037388e-01 -3.68269801e+00 -4.00777429e-01  1.16721180e+00\n",
            " -1.54987681e+00 -3.00356418e-01  2.07817805e+00  4.94421519e-01\n",
            " -1.85207218e+00 -4.84002531e-02  1.27830863e-01  6.27087712e-01\n",
            " -7.68669963e-01 -2.21604726e+00  1.37683976e+00 -1.57534742e+00\n",
            " -7.84837522e-01  1.25446770e+00 -1.70874783e+00 -1.82456607e+00\n",
            "  4.20378879e-01  1.36167926e+00  1.91455656e+00  3.78233790e-01\n",
            " -1.43511033e+00  4.84851271e-01  1.15841453e+00  8.38955373e-01\n",
            "  5.87165704e-01 -4.94616468e-01  2.22478443e+00  2.31627971e-02\n",
            " -1.43839069e+00  6.70529962e-01  1.47645152e+00 -9.75559354e-02\n",
            "  2.48321187e+00 -2.03466558e+00 -3.56072020e-01 -8.54520977e-01\n",
            " -7.25998282e-02  9.91591215e-02  6.50500059e-01 -5.83789863e-01\n",
            " -2.01577008e-01 -3.65309387e-01 -1.20881696e+00  1.91838965e-01\n",
            "  1.11862276e-01  1.28564483e+00  6.48953915e-01 -1.00620735e+00\n",
            "  1.21487334e+00  9.75212187e-01  4.98805150e-01 -1.52942687e-01\n",
            "  6.72284752e-01 -8.37898117e-01 -4.16527960e-01  6.12237241e-01\n",
            " -2.03571004e+00 -5.64721301e-01 -6.68374926e-01  1.07843268e+00\n",
            "  1.13803792e+00  2.34560388e+00 -4.67283905e-01 -2.53976309e+00\n",
            "  8.12048689e-01 -1.09020397e+00  1.54459754e+00  2.65464985e+00\n",
            " -7.86466777e-01  7.85542712e-01  1.58204943e+00  5.33134297e-01\n",
            "  9.22654554e-01 -1.04410973e+00  1.84306026e-01  2.12536663e-01\n",
            "  9.93446968e-02 -8.63265783e-01 -8.36232126e-01  9.38379303e-01\n",
            "  2.02246189e-01  1.15581334e+00  1.43766430e+00 -4.31174308e-01\n",
            " -9.80917782e-01 -1.31173572e+00  1.93357188e-03  4.21341702e-01\n",
            " -9.90253001e-01 -3.84278461e-01 -1.15991288e+00  1.13057181e+00\n",
            " -5.83181059e-01 -1.59942454e+00  5.15699476e-01  1.31913868e+00\n",
            " -3.05330440e-01 -3.68479624e-01  2.70546228e-02  1.00789528e+00\n",
            "  6.61560766e-01  2.09092230e+00 -8.00739750e-01 -1.50305894e+00\n",
            " -4.56248730e-01  2.67375633e-02  1.17398885e+00  2.87635207e-01\n",
            "  9.18178275e-01 -3.02510854e-01  1.28056517e+00 -1.44844422e+00\n",
            "  8.35372169e-01 -1.61041968e-01  2.22836065e+00 -1.25159514e+00\n",
            "  1.65033525e+00  3.30381258e-01  1.95123577e+00 -1.30696899e+00\n",
            "  2.66428888e-02  1.03173420e+00 -1.63742703e+00 -2.08222724e-01\n",
            " -1.15079454e+00 -2.16082954e+00 -1.37640834e-01  1.92430470e-01\n",
            "  1.76940972e+00  4.25789833e-01  1.19841047e-01 -2.18476191e-01\n",
            " -1.35700130e+00 -1.00228076e+00  2.49297157e-01  7.63084114e-01\n",
            " -5.33406764e-01  6.59738615e-01  8.82726848e-01 -8.12430203e-01\n",
            "  2.51689017e-01 -9.94461894e-01  1.21375620e+00 -4.55007643e-01\n",
            " -4.57954541e-01  1.98157209e+00  1.78067006e-01  6.05995998e-01\n",
            "  6.78149946e-02 -1.45269555e+00 -1.27065516e+00  1.90793341e+00\n",
            "  6.13099799e-01 -1.69027060e-01 -6.28735378e-01 -6.31090790e-01\n",
            "  1.55524051e+00 -2.15472475e-01 -6.84849702e-01  4.99820996e-01\n",
            "  1.96323717e+00  2.96189005e-01  1.85929298e+00  1.40782392e+00\n",
            " -1.15219712e+00  1.67372602e+00  1.34153491e+00  6.14453144e-01\n",
            " -5.44722363e-01  1.40966392e+00  9.25186361e-02  1.45906603e+00\n",
            " -2.38314912e-01 -8.86740118e-01 -3.15895408e-01 -2.78806202e-01\n",
            " -6.57601178e-01 -8.68141711e-01 -3.27251948e-01  8.65597814e-01\n",
            "  4.48733862e-01  2.35855317e+00  1.23434165e-01 -7.74819739e-02\n",
            " -1.55999637e+00 -8.75566736e-01  1.19131517e+00 -3.72749640e-01\n",
            "  2.92995613e-01  5.89443058e-01 -1.03985191e+00 -6.96430214e-01\n",
            " -9.57700133e-01 -3.18870224e-01 -5.81027806e-01  4.35709174e-01\n",
            " -2.80020371e-01  5.36625370e-01  8.48061632e-01 -3.70963149e-01\n",
            " -4.21748381e-01 -1.19685948e+00 -2.20380944e+00  3.92598204e-01\n",
            " -2.53228541e-01 -3.18357341e-01 -2.05151916e+00  7.89988607e-01\n",
            " -8.23338956e-01  5.22234067e-01  4.55259256e-01  4.34126098e-01\n",
            " -1.22551575e+00  5.15473515e-01  1.41288686e+00 -2.49610767e-02\n",
            "  1.84673858e+00  4.17821586e-01  2.24084701e-01 -3.53349566e-01\n",
            " -1.08502981e+00 -2.04974674e-01 -1.28432894e+00  1.14757806e-01\n",
            "  9.74009722e-01 -1.26701888e+00  2.00748712e-01  1.02449819e-01\n",
            "  1.95147812e-01 -8.54850426e-01  8.94861221e-02  5.58104321e-01\n",
            " -4.22235578e-02 -1.53354764e+00  1.94546312e+00 -9.29926366e-01\n",
            "  1.01617122e+00 -2.15997607e-01  4.09804739e-01  3.17823157e-01\n",
            " -1.31208700e+00 -2.79026404e-01 -1.79296571e+00 -4.27167054e-01\n",
            " -9.84817803e-01 -8.86773795e-01  1.29181577e-01 -1.93774939e-01\n",
            " -2.04041296e+00 -1.67806253e+00  3.00091490e-01 -6.38263389e-01\n",
            "  4.34616841e-01 -4.77252156e-01 -1.06530435e+00  9.04424012e-01\n",
            "  7.04064205e-01  6.99621908e-01 -3.44633907e-02 -1.05854461e+00\n",
            " -1.40041634e+00  1.03063345e+00  3.77409622e-01  1.21463206e+00\n",
            "  2.25604691e-01  2.24360585e+00  6.68164864e-01  6.18481815e-01\n",
            " -9.50087771e-01 -4.91134629e-01  1.18280689e+00  6.72731795e-01\n",
            " -1.89804667e+00  8.46179605e-01  2.90858539e-01  1.12164900e+00\n",
            " -5.24247527e-01  5.24421654e-01  7.59534627e-01  6.76070511e-01\n",
            "  1.68806194e+00  8.19247961e-02  8.19070749e-02 -1.04986328e+00\n",
            "  7.60968402e-01 -1.03409928e+00 -5.46093017e-01 -1.44065937e+00\n",
            " -5.37180804e-01  1.46954998e+00  8.04521799e-01 -4.49054316e-01\n",
            "  9.12972614e-01  2.48178542e-01 -3.44304323e+00 -1.35489538e+00\n",
            "  9.43194389e-01  2.50631362e-01 -6.91425204e-02 -2.55996346e-01\n",
            "  4.60387111e-01  2.46004656e-01 -5.81855357e-01 -6.11362010e-01\n",
            "  2.03780584e-01 -5.50391059e-01  1.18943244e-01  5.39657176e-01\n",
            "  1.07670367e+00  1.36069220e+00 -3.72330710e-01 -8.30883503e-01\n",
            " -9.76440907e-01  1.88265678e-01 -1.71015632e+00  5.34232862e-01\n",
            " -9.13481891e-01 -1.10702091e+00 -2.04881176e-01 -9.36782360e-03\n",
            "  1.08203828e+00 -8.22540641e-01  6.67609438e-01 -1.65359491e+00\n",
            " -1.82817116e-01  1.35478598e+00  1.30641016e+00  1.40007125e+00\n",
            "  9.46374064e-01 -2.67913070e-01  9.20441053e-01 -6.97425753e-01\n",
            " -5.40860444e-02 -1.28908858e+00 -6.35089144e-01 -2.09993672e+00\n",
            "  6.50558783e-01  1.18119767e+00 -5.21475062e-01 -1.64800057e-01\n",
            " -9.97721165e-01  9.19342041e-04  8.01333755e-01  9.29778248e-01\n",
            "  1.52452442e+00  1.37409866e-02  9.62355075e-01  1.49863154e-01\n",
            "  2.17928290e-02 -8.99061203e-01 -4.66462910e-01 -8.01045120e-01\n",
            " -2.20228121e-01  1.69970810e+00 -1.68893749e+00 -1.08515292e-01\n",
            "  3.18759851e-01 -2.74016976e+00  8.78916949e-01 -3.07183377e-02\n",
            " -2.48358047e+00 -9.38170135e-01 -2.12613398e+00  1.58509541e+00\n",
            " -1.65847200e+00  3.66349641e-01  1.37096485e+00 -7.88009632e-01\n",
            "  3.12223434e-02 -1.73750818e+00 -5.85524397e-01  1.63449887e-01\n",
            " -2.93958050e+00  8.86092953e-01 -3.13986324e-01 -5.33847574e-01\n",
            "  1.84016751e-01  2.21364635e+00  7.10471570e-01 -1.09809339e-02\n",
            "  6.49155855e-01 -9.21418570e-01 -4.21622753e-01  1.32904217e+00\n",
            "  6.77254535e-02  1.12236619e+00  4.47264776e-01 -1.53242745e-01\n",
            "  2.63027698e-01 -8.02242056e-01  4.16011006e-01  1.46752059e+00\n",
            " -4.28011462e-01  1.11074963e+00 -8.77070487e-01  5.40260243e-01\n",
            " -2.86289528e-01 -6.36920579e-01 -1.23179268e-01 -2.13876015e+00\n",
            " -1.39755747e+00  1.92606211e-01  1.20943678e+00 -1.02696308e+00\n",
            "  3.58126175e-01 -4.37042788e-02 -2.28873217e+00 -9.37192649e-01\n",
            "  1.83521722e-01  1.02333505e+00  5.56163007e-01 -1.24809518e-01\n",
            " -1.25402436e+00 -7.59659640e-01  1.57626355e+00 -2.15265197e+00\n",
            " -1.31986696e+00  5.56259900e-01 -4.28397298e-01 -1.10460222e-02\n",
            "  1.82952219e+00  5.79611719e-01 -3.36936519e-01 -4.35577631e-02\n",
            " -3.60838309e-01  1.22453153e+00  4.47804850e-01  2.24563785e-01\n",
            "  1.19750598e+00 -2.96162963e-02 -3.86087865e-01 -8.91723722e-01\n",
            " -1.43958348e+00 -1.67812717e+00 -4.97670472e-01 -1.55790138e+00\n",
            " -1.98336226e+00  3.69447052e-01 -4.58238989e-01  1.43372774e+00\n",
            "  1.11944616e-01  1.10256222e+00  1.15274549e+00  4.61643822e-01\n",
            "  7.19371766e-01  1.19446260e+00 -1.16556695e+00  8.24766755e-01\n",
            " -3.95446360e-01  1.83320522e+00 -1.56399059e+00  8.31286162e-01\n",
            " -3.30977321e-01 -1.35950714e+00 -6.72717318e-01  1.18625760e-02\n",
            " -1.30388549e+00  4.83340725e-01 -6.88658953e-01 -1.89752892e-01\n",
            " -6.58101402e-02 -8.04091036e-01  2.37040108e-01 -2.30255479e+00\n",
            " -7.08203763e-01  8.11580271e-01  1.65872180e+00  3.78668979e-01\n",
            "  1.24708506e+00 -1.85140349e-01 -4.72301722e-01  1.03854129e+00\n",
            " -5.83673999e-01  6.12295046e-01 -9.52564791e-01 -9.53119397e-02\n",
            " -1.77028555e+00 -9.46760871e-01  7.70343542e-01 -7.48886973e-01\n",
            "  1.66686249e+00  4.79531318e-01  1.22318301e+00 -8.65422904e-01\n",
            " -2.45289856e+00 -2.66597703e-01 -1.15409791e-02 -6.93154097e-01\n",
            " -3.88200545e+00 -2.84516954e+00 -1.95028442e+00 -3.18486169e-02\n",
            "  5.82057251e-01  2.55417824e-02 -2.32424140e+00 -5.73546246e-01\n",
            " -1.85214108e+00  7.36438185e-01  6.16704583e-01 -1.87547479e-01\n",
            "  7.76985884e-01  1.14133072e+00 -6.21933170e-01  5.31771712e-01\n",
            " -1.89971751e+00 -1.37418336e+00  5.56305554e-01  2.24844959e-01\n",
            "  6.30683810e-01 -3.78012542e-01  2.11262107e-02 -4.22661811e-01\n",
            "  1.99397725e+00  2.71405065e+00  8.81294370e-01  7.93510765e-01\n",
            " -1.64898187e-01 -6.63308531e-01 -8.56706232e-01  9.62178171e-01\n",
            " -1.15232718e+00  1.65942478e+00  7.95327157e-01 -6.34401530e-01\n",
            " -5.06259933e-01 -2.08909348e-01  4.31773663e-02 -1.59769720e+00\n",
            "  7.42970593e-02 -2.43256014e-01  1.55051422e+00  2.72239037e-01\n",
            "  1.60416571e-01 -1.60617715e+00  1.40117842e+00 -1.63947016e-01\n",
            "  3.04866783e-01  7.06250787e-01  5.38541570e-01  8.21618840e-01\n",
            " -1.69141710e-01 -7.63856441e-01 -1.11801898e+00  1.07183844e+00\n",
            " -3.02137107e-01  1.35484040e-02 -9.58130717e-01 -1.08405054e-01\n",
            "  2.52232984e-01  1.15274653e-01  3.95446926e-01 -1.63888657e+00\n",
            "  2.06274603e-01  5.30776441e-01 -9.05090898e-01 -3.05823231e+00\n",
            " -3.06892288e+00  7.73161143e-01 -1.62033975e-01 -3.89357835e-01\n",
            "  7.30330139e-01 -7.78404146e-01 -7.46599913e-01 -2.42101774e-01\n",
            " -1.73888201e+00 -9.64723185e-01 -3.13600093e-01 -3.21239516e-01\n",
            " -3.76376808e-02  4.57721621e-01  1.27345231e+00  1.43293440e+00\n",
            "  1.77346274e-01 -2.04077578e+00  7.65660852e-01  1.12254888e+00\n",
            " -1.05618250e+00 -1.25347661e-01  1.07858516e+00  1.05303451e-01\n",
            " -1.13336931e+00  1.14585526e+00  8.12968567e-01 -9.04976800e-01\n",
            " -1.17896977e+00 -5.40454634e-01  5.63266557e-02  1.03408179e+00\n",
            "  2.09043682e-01  6.24132860e-01  9.50708613e-01 -9.02355470e-01\n",
            " -3.50414101e-01  1.00367928e+00  5.34230381e-01  1.48335699e-01\n",
            " -1.27280515e-01  3.36145721e-01  7.93379098e-01 -2.90832296e-01\n",
            "  1.83721167e+00  1.19696891e-01  7.97479792e-01  3.08272162e-01\n",
            "  4.05834556e-01  5.34651428e-01  6.35518275e-01  2.49082454e-01\n",
            "  9.50387001e-01 -4.36617345e-01  2.89642662e-01 -8.83978307e-01\n",
            "  4.37567361e-01 -1.54829460e+00 -6.85361177e-02 -1.34825709e+00\n",
            "  3.59629524e+00  1.67689160e+00 -2.76055090e-01 -9.54822786e-02\n",
            " -2.64339365e-01 -4.91890058e-01  5.23741737e-01 -8.68415236e-02\n",
            " -5.45390472e-01  1.03592506e+00 -9.93771613e-01 -7.64461428e-01\n",
            "  1.74392229e+00  6.14700645e-01  6.68173432e-01  8.69872242e-01\n",
            " -9.51909497e-01 -1.39069954e+00  5.41173476e-01  8.76533985e-03\n",
            " -1.51546724e+00 -6.04312837e-01 -5.07888570e-02 -2.01328942e+00\n",
            "  2.73982435e-02  1.31745422e+00 -3.08809116e-01 -2.22284541e-01\n",
            " -2.36567833e-01 -2.34172291e+00  4.00942318e-01  4.87469442e-01\n",
            " -5.83210140e-02 -1.50874175e-01  5.06278709e-01  3.74156371e-01\n",
            "  1.63358510e+00  3.83209828e-01 -2.82819383e-01 -3.97392474e-01\n",
            "  1.51251949e-01 -7.75056273e-01  2.04425144e+00 -6.33876860e-01\n",
            " -1.00057894e+00  2.03965076e-01  2.67273225e-02  1.02872041e+00\n",
            "  6.20325096e-02 -1.13866988e+00  1.33817902e+00 -5.89294448e-01\n",
            " -9.48315680e-01 -1.48617345e+00  4.92881373e-01  6.39918426e-01\n",
            "  5.38740307e-01  1.02872515e+00  5.15660167e-01  8.62135619e-01\n",
            "  2.88103223e-01 -1.01711011e+00 -1.10375243e+00 -8.66882537e-01\n",
            "  3.47698420e-01  4.31780398e-01 -4.89920558e-01 -8.14154714e-01\n",
            " -5.73334903e-01 -8.29452246e-01  6.68508723e-01 -1.28142044e-01\n",
            "  6.91292010e-01 -1.65191329e+00  8.76517743e-01 -5.22035435e-01\n",
            "  4.52486046e-01  1.87801766e+00 -2.00078636e-01  9.38336492e-01\n",
            " -2.87221766e+00  6.32252753e-01  1.77910507e-01 -1.89405543e+00\n",
            " -9.31439161e-01 -1.55054045e+00 -1.43624848e+00  8.50725770e-01\n",
            "  2.90125683e-02  8.36343944e-01 -2.09709352e+00  3.35675329e-02]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLprvVUK458L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "label_list = [\"GoodsServices\",\n",
        "        \"SearchAndRescue\",\n",
        "        \"InformationWanted\",\n",
        "        \"Volunteer\",\n",
        "        \"FundRaising\",\n",
        "        \"Donations\",\n",
        "        \"MovePeople\",\n",
        "        \"FirstPartyObservation\",\n",
        "        \"ThirdPartyObservation\",\n",
        "        \"Weather\",\n",
        "        \"EmergingThreats\",\n",
        "        \"NewSubEvent\",\n",
        "        \"MultimediaShare\",\n",
        "        \"ServiceAvailable\",\n",
        "        \"Factoid\",\n",
        "        \"Official\",\n",
        "        \"CleanUp\",\n",
        "        \"Hashtags\",\n",
        "        \"ContextualInformation\",\n",
        "        \"News\",\n",
        "        \"Advice\",\n",
        "        \"Sentiment\",\n",
        "        \"Discussion\",\n",
        "        \"Irrelevant\",\n",
        "        \"OriginalEvent\"]\n",
        "important_list = [\"Low\",\n",
        "        \"Medium\",\n",
        "        \"High\",\n",
        "        \"Critical\"\n",
        "       ]\n",
        "tweets = []\n",
        "path = '/content/gdrive/My Drive/Colab_Notebooks/code/bert-version/src/attention/data/ll.csv'\n",
        "with open(path, 'r', encoding='utf-8') as f:\n",
        "    reader = csv.reader(f)\n",
        "    for line in reader:\n",
        "        tweet_full = line\n",
        "        tweets.append({\n",
        "            'id': tweet_full[0],\n",
        "            'label':tweet_full[1],\n",
        "            'important':tweet_full[2],\n",
        "            'text': tweet_full[3].lower(),\n",
        "            # 'name': tweet_full['user']['name'].split()[0]\n",
        "            })\n",
        "tweet_list = []\n",
        "text_list = []\n",
        "label_List = []\n",
        "for i in range(len(tweets)):\n",
        "        sentences = []\n",
        "        text_list.append(tweets[i]['text'])\n",
        "        tweets_vector = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "        tweets_label = eval(tweets[i]['label'])\n",
        "        p = 0\n",
        "        for j in label_list:\n",
        "            for k in tweets_label:\n",
        "                if k == j:\n",
        "                    tweets_vector[p] = 1\n",
        "                    sentences.append(LabelTable[j][2])\n",
        "            p+=1\n",
        "        tweet_list.append(tweets_vector)\n",
        "        sentence_embeddings = model.encode(sentences)\n",
        "        temple = np.zeros(768)\n",
        "        for embedding in  sentence_embeddings:\n",
        "             temple+=embedding\n",
        "        label_List.append(temple)\n",
        "text_numpy = model.encode(text_list)\n",
        "numpy_label_list = np.array(tweet_list)\n",
        "numpy_text_list = np.array(text_numpy)\n",
        "numpy_label_text_list = np.array(label_List)\n",
        "np.save('./data/label_text.npy',numpy_label_text_list)\n",
        "np.save('./data/label1.npy',numpy_label_list)\n",
        "np.save('./data/text1.npy',numpy_text_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xz-18XLPqZnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cB8lQscg6JS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "lr = 0.001\n",
        "epochs = 1000\n",
        "batch_size = 16\n",
        "seed = 1111\n",
        "cuda_able = True\n",
        "save = \n",
        "dropout = 0.5\n",
        "embed_dim = 64\n",
        "hidden_size = 32\n",
        "bidirectional = True\n",
        "weight_decay = 0.001\n",
        "attention_size = 16\n",
        "sequence_length = 16\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "use_cuda = torch.cuda.is_available() and cuda_able\n",
        "\n",
        "\n",
        "###################################################\n",
        "#load data\n",
        "\n",
        "from data_loder import DataLoader\n",
        "\n",
        "data = np.load(\"./data/text.npy\")\n",
        "label = np.load(\"./data/label.npy\")\n",
        "\n",
        "\n",
        "\n",
        "training_data = DataLoader(data,\n",
        "                           label,\n",
        "                           batch_size=batch_size,\n",
        "                           cuda=use_cuda)\n",
        "validation_data = DataLoader(data,\n",
        "                             label,\n",
        "                             batch_size=batch_size,\n",
        "                             shuffle=False,\n",
        "                             cuda=use_cuda)\n",
        "\n",
        "\n",
        "###############################################\n",
        "#build model\n",
        "\n",
        "import model\n",
        "lstm_attn = model.bilstm_attn(batch_size=batch_size,\n",
        "                                  output_size=output_size,\n",
        "                                  hidden_size=hidden_size,\n",
        "                                  vocab_size=vocab_size,\n",
        "                                  embed_dim=embed_dim,\n",
        "                                  bidirectional=bidirectional,\n",
        "                                  dropout=dropout,\n",
        "                                  use_cuda=use_cuda,\n",
        "                                  attention_size=attention_size,\n",
        "                                  sequence_length=sequence_length)\n",
        "if use_cuda:\n",
        "    lstm_attn = lstm_attn.cuda()\n",
        "\n",
        "optimizer = torch.optim.Adam(lstm_attn.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "###################################################\n",
        "#training\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "train_loss = []\n",
        "valid_loss = []\n",
        "accuracy = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def evaluate():\n",
        "    lstm_attn.eval()\n",
        "    corrects = eval_loss = 0\n",
        "    _size = validation_data.sents_size\n",
        "\n",
        "    for data, label in tqdm(validation_data, mininterval=0.2,\n",
        "                desc='Evaluate Processing', leave=False):\n",
        "\n",
        "        pred = lstm_attn(data)\n",
        "        loss = criterion(pred, label)\n",
        "\n",
        "        eval_loss += loss.data\n",
        "        corrects += (torch.max(pred, 1)[1].view(label.size()).data == label.data).sum()\n",
        "    return eval_loss[0]/_size, corrects, corrects*100.0/_size, _size\n",
        "\n",
        "\n",
        "def train():\n",
        "    lstm_attn.train()\n",
        "    total_loss = 0\n",
        "    for data, label in tqdm(training_data, mininterval=1,\n",
        "                desc='Train Processing', leave=False):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        target = lstm_attn(data)\n",
        "        loss = criterion(target, label)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.data\n",
        "    return total_loss[0]/training_data.sents_size\n",
        "\n",
        "#################################################\n",
        "#saving\n",
        "best_acc = None\n",
        "total_start_time = time.time()\n",
        "\n",
        "try:\n",
        "    print('-' * 90)\n",
        "    for epoch in range(1, epochs+1):\n",
        "        epoch_start_time = time.time()\n",
        "        loss = train()\n",
        "        train_loss.append(loss*1000.)\n",
        "\n",
        "        print('| start of epoch {:3d} | time: {:2.2f}s | loss {:5.6f}'.format(epoch,\n",
        "                                                                              time.time() - epoch_start_time,\n",
        "                                                                              loss))\n",
        "\n",
        "        loss, corrects, acc, size = evaluate()\n",
        "        valid_loss.append(loss*1000.)\n",
        "        accuracy.append(acc)\n",
        "\n",
        "        print('-' * 10)\n",
        "        print('| end of epoch {:3d} | time: {:2.2f}s | loss {:.4f} | accuracy {}%({}/{})'.format(epoch,\n",
        "                                                                                                 time.time() - epoch_start_time,\n",
        "                                                                                                 loss,\n",
        "                                                                                                 acc,\n",
        "                                                                                                 corrects,\n",
        "                                                                                                 size))\n",
        "        print('-' * 10)\n",
        "        if not best_acc or best_acc < corrects:\n",
        "            best_acc = corrects\n",
        "            model_state_dict = lstm_attn.state_dict()\n",
        "            model_source = {\n",
        "                \"model\": model_state_dict,\n",
        "                \"src_dict\": data['dict']['train']\n",
        "            }\n",
        "            torch.save(model_source, save)\n",
        "except KeyboardInterrupt:\n",
        "    print(\"-\"*90)\n",
        "    print(\"Exiting from training early | cost time: {:5.2f}min\".format((time.time() - total_start_time)/60.0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gWoWziH5-c3",
        "colab_type": "text"
      },
      "source": [
        "# 新段落"
      ]
    }
  ]
}